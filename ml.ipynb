{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:05<00:00, 68.28it/s]\n",
      "100%|██████████| 646/646 [00:09<00:00, 65.99it/s]\n",
      "100%|██████████| 440/440 [00:07<00:00, 62.05it/s]\n",
      "100%|██████████| 581/581 [00:08<00:00, 72.11it/s]\n",
      "100%|██████████| 604/604 [00:09<00:00, 65.92it/s]\n",
      "100%|██████████| 549/549 [00:08<00:00, 63.92it/s]\n",
      "100%|██████████| 530/530 [00:07<00:00, 69.28it/s]\n",
      "100%|██████████| 390/390 [00:05<00:00, 68.43it/s]\n",
      "100%|██████████| 493/493 [00:08<00:00, 55.20it/s]\n",
      "100%|██████████| 429/429 [00:06<00:00, 66.63it/s]\n",
      "100%|██████████| 620/620 [00:08<00:00, 73.94it/s]\n",
      "100%|██████████| 490/490 [00:09<00:00, 49.20it/s]\n",
      "100%|██████████| 432/432 [00:07<00:00, 59.12it/s]\n",
      "100%|██████████| 400/400 [00:06<00:00, 64.36it/s]\n",
      "100%|██████████| 340/340 [00:05<00:00, 62.97it/s]\n",
      "100%|██████████| 96/96 [00:01<00:00, 67.37it/s]\n",
      "100%|██████████| 162/162 [00:02<00:00, 71.45it/s]\n",
      "100%|██████████| 111/111 [00:01<00:00, 71.35it/s]\n",
      "100%|██████████| 146/146 [00:01<00:00, 75.92it/s]\n",
      "100%|██████████| 151/151 [00:02<00:00, 62.47it/s]\n",
      "100%|██████████| 138/138 [00:02<00:00, 57.52it/s]\n",
      "100%|██████████| 133/133 [00:01<00:00, 67.15it/s]\n",
      "100%|██████████| 98/98 [00:01<00:00, 68.20it/s]\n",
      "100%|██████████| 124/124 [00:02<00:00, 59.70it/s]\n",
      "100%|██████████| 108/108 [00:01<00:00, 65.62it/s]\n",
      "100%|██████████| 156/156 [00:02<00:00, 67.51it/s]\n",
      "100%|██████████| 123/123 [00:02<00:00, 54.44it/s]\n",
      "100%|██████████| 109/109 [00:01<00:00, 58.82it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.90it/s]\n",
      "100%|██████████| 86/86 [00:01<00:00, 68.45it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'archive'\n",
    "SUBDIRS = [\"train\", \"test\"]\n",
    "CATEGORIES = [\"american_football\",\"billiard_ball\",\"bowling_ball\",\"cricket_ball\",\"football\",\"golf_ball\",\"hockey_ball\",\"hockey_puck\",\"rugby_ball\",\"shuttlecock\",\"table_tennis_ball\",\"tennis_ball\",\"volleyball\",\"baseball\", \"basketball\"]\n",
    "\n",
    "dataset = {\n",
    "    \"train\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "\n",
    "for subdir in SUBDIRS:\n",
    "    x = 0\n",
    "    for category in CATEGORIES: \n",
    "        path = os.path.join(DATADIR, subdir, category)\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            img_array = cv2.imread(os.path.join(path, img)).astype(np.float32)/255.0\n",
    "            IMG_SIZE = 150\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE,IMG_SIZE))\n",
    "            new_array_rgb = cv2.cvtColor(new_array, cv2.COLOR_BGR2RGB)\n",
    "            dataset[subdir].append([new_array_rgb,x])\n",
    "\n",
    "        x += 1\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  ...\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]]\n",
      "\n",
      " [[0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  ...\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]]\n",
      "\n",
      " [[0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  ...\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  ...\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]]\n",
      "\n",
      " [[0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  ...\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]]\n",
      "\n",
      " [[0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  ...\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]\n",
      "  [0.9490196  0.92941177 0.9254902 ]]]\n",
      "(225, 225, 3)\n"
     ]
    }
   ],
   "source": [
    "print (img_array)\n",
    "print (img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "for features, label in dataset[\"train\"]: \n",
    "    Xtrain.append(features)\n",
    "    Ytrain.append(label)\n",
    "\n",
    "Xtrain = np.array(Xtrain).reshape(-1, IMG_SIZE,IMG_SIZE, 3)\n",
    "y = np.array(Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\youjo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        Conv2D(32, (4, 4), activation=\"relu\", input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(15, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 224ms/step - accuracy: 0.0956 - loss: 2.6647\n",
      "Epoch 2/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 220ms/step - accuracy: 0.1639 - loss: 2.5144\n",
      "Epoch 3/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 223ms/step - accuracy: 0.2364 - loss: 2.3710\n",
      "Epoch 4/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 214ms/step - accuracy: 0.3150 - loss: 2.1159\n",
      "Epoch 5/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 213ms/step - accuracy: 0.4121 - loss: 1.8310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27b0a4090a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain,y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 384/384 [00:04<00:00, 84.59it/s] \n",
      "100%|██████████| 646/646 [00:07<00:00, 86.97it/s] \n",
      "100%|██████████| 440/440 [00:05<00:00, 81.58it/s]\n",
      "100%|██████████| 581/581 [00:06<00:00, 93.73it/s] \n",
      "100%|██████████| 604/604 [00:07<00:00, 82.90it/s] \n",
      "100%|██████████| 549/549 [00:08<00:00, 68.29it/s]\n",
      "100%|██████████| 530/530 [00:07<00:00, 75.60it/s]\n",
      "100%|██████████| 390/390 [00:05<00:00, 73.96it/s]\n",
      "100%|██████████| 493/493 [00:08<00:00, 57.99it/s]\n",
      "100%|██████████| 429/429 [00:06<00:00, 68.41it/s]\n",
      "100%|██████████| 620/620 [00:07<00:00, 79.83it/s]\n",
      "100%|██████████| 490/490 [00:09<00:00, 53.58it/s]\n",
      "100%|██████████| 432/432 [00:05<00:00, 75.08it/s] \n",
      "100%|██████████| 400/400 [00:03<00:00, 113.88it/s]\n",
      "100%|██████████| 340/340 [00:03<00:00, 108.19it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 117.49it/s]\n",
      "100%|██████████| 162/162 [00:01<00:00, 138.52it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 129.87it/s]\n",
      "100%|██████████| 146/146 [00:01<00:00, 143.86it/s]\n",
      "100%|██████████| 151/151 [00:01<00:00, 101.16it/s]\n",
      "100%|██████████| 138/138 [00:01<00:00, 101.21it/s]\n",
      "100%|██████████| 133/133 [00:01<00:00, 116.45it/s]\n",
      "100%|██████████| 98/98 [00:00<00:00, 118.94it/s]\n",
      "100%|██████████| 124/124 [00:01<00:00, 92.57it/s] \n",
      "100%|██████████| 108/108 [00:00<00:00, 110.91it/s]\n",
      "100%|██████████| 156/156 [00:01<00:00, 117.74it/s]\n",
      "100%|██████████| 123/123 [00:01<00:00, 83.46it/s] \n",
      "100%|██████████| 109/109 [00:01<00:00, 93.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 115.35it/s]\n",
      "100%|██████████| 86/86 [00:00<00:00, 115.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 291ms/step - accuracy: 0.0920 - loss: 17.0622\n",
      "Epoch 2/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 288ms/step - accuracy: 0.0855 - loss: 2.6822\n",
      "Epoch 3/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 286ms/step - accuracy: 0.1171 - loss: 2.6554\n",
      "Epoch 4/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 284ms/step - accuracy: 0.1192 - loss: 2.6303\n",
      "Epoch 5/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 282ms/step - accuracy: 0.1375 - loss: 2.5960\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.1830 - loss: 2.5729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6307003498077393, 0.11732754111289978]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(data_dir):\n",
    "    data = []\n",
    "    for category in CATEGORIES: \n",
    "        path = os.path.join(data_dir, category)\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in tqdm(os.listdir(path)): \n",
    "            try: \n",
    "                img_array = cv2.imread(os.path.join(path, img))\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append([new_array, class_num])\n",
    "            except Exception as e: \n",
    "                pass\n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "train_data = load_data(os.path.join(DATADIR, 'train'))\n",
    "test_data = load_data(os.path.join(DATADIR, 'test'))\n",
    "\n",
    "\n",
    "X_train = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y_train = np.array([i[1] for i in train_data])\n",
    "\n",
    "X_test = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "y_test = np.array([i[1] for i in test_data])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.11732753938077133\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m91884032/91884032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=xception, built=True>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 2\n",
    "keras.applications.Xception(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 264ms/step - accuracy: 0.1495 - loss: 2.5517\n",
      "Epoch 2/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 286ms/step - accuracy: 0.1854 - loss: 2.4550\n",
      "Epoch 3/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 270ms/step - accuracy: 0.2163 - loss: 2.3857\n",
      "Epoch 4/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 263ms/step - accuracy: 0.2627 - loss: 2.2698\n",
      "Epoch 5/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 241ms/step - accuracy: 0.2996 - loss: 2.1420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27c51fd6db0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step\n",
      "Accuracy:  0.17110266159695817\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "pred = np.argmax(prediction, axis=1)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m96112376/96112376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=inception_v3, built=True>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 3\n",
    "keras.applications.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 255ms/step - accuracy: 0.3499 - loss: 1.9875\n",
      "Epoch 2/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 263ms/step - accuracy: 0.4090 - loss: 1.8140\n",
      "Epoch 3/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 278ms/step - accuracy: 0.4477 - loss: 1.6768\n",
      "Epoch 4/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 279ms/step - accuracy: 0.4807 - loss: 1.5908\n",
      "Epoch 5/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 281ms/step - accuracy: 0.5215 - loss: 1.4779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27c545a3ec0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n",
      "Accuracy:  0.21455730581205867\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "pred = np.argmax(prediction, axis=1)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=vgg16, built=True>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 4\n",
    "keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 218ms/step - accuracy: 0.5417 - loss: 1.4152\n",
      "Epoch 2/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 217ms/step - accuracy: 0.5831 - loss: 1.2684\n",
      "Epoch 3/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 217ms/step - accuracy: 0.6124 - loss: 1.2156\n",
      "Epoch 4/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 218ms/step - accuracy: 0.6108 - loss: 1.2083\n",
      "Epoch 5/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 238ms/step - accuracy: 0.6153 - loss: 1.2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27c5de38590>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n",
      "Accuracy:  0.24932102118413904\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "pred = np.argmax(prediction, axis=1)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf.h5\n",
      "\u001b[1m17225924/17225924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Functional name=mobilenet_1.00_224, built=True>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model 5\n",
    "keras.applications.MobileNet(\n",
    "    input_shape=None,\n",
    "    alpha=1.0,\n",
    "    depth_multiplier=1,\n",
    "    dropout=0.001,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 228ms/step - accuracy: 0.6446 - loss: 1.0918\n",
      "Epoch 2/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 221ms/step - accuracy: 0.6631 - loss: 1.0531\n",
      "Epoch 3/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 217ms/step - accuracy: 0.6849 - loss: 0.9947\n",
      "Epoch 4/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 266ms/step - accuracy: 0.6935 - loss: 0.9658\n",
      "Epoch 5/5\n",
      "\u001b[1m229/229\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 231ms/step - accuracy: 0.7074 - loss: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27c5e203c80>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step\n",
      "Accuracy:  0.265073329712113\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "pred = np.argmax(prediction, axis=1)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print (\"Accuracy: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
